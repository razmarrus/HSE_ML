{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: Classification quality metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is dedicated to various **metrics of classification quality:  accuracy, presition, recall, f1-score, AUC-ROC**, etc.\n",
    "Therefore, last few tasks are focused on comparation efficenty of classification algorithms with metrics above.  \n",
    "Let's take a look at original six tasks presented in Russian.\n",
    "\n",
    "**Tasks will be duplicated in english further in this assignment**\n",
    "\n",
    "1.     Загрузите файл classification.csv. В нем записаны истинные классы объектов выборки (колонка true) и ответы некоторого классификатора (колонка pred).\n",
    "\n",
    "2. Заполните таблицу ошибок классификации:\n",
    "    Для этого подсчитайте величины TP, FP, FN и TN согласно их определениям. Например, FP — это количество объектов, имеющих класс 0, но отнесенных алгоритмом к классу 1. Ответ в данном вопросе — четыре числа через пробел.\n",
    "3. Посчитайте основные метрики качества классификатора:\n",
    "\n",
    "    Accuracy (доля верно угаданных) — sklearn.metrics.accuracy_score\n",
    "    Precision (точность) — sklearn.metrics.precision_score\n",
    "    Recall (полнота) — sklearn.metrics.recall_score\n",
    "    F-мера — sklearn.metrics.f1_score\n",
    "4. Имеется четыре обученных классификатора. В файле scores.csv записаны истинные классы и значения степени принадлежности положительному классу для каждого классификатора на некоторой выборке:\n",
    "\n",
    "    для логистической регрессии — вероятность положительного класса (колонка score_logreg),\n",
    "    для SVM — отступ от разделяющей поверхности (колонка score_svm),\n",
    "    для метрического алгоритма — взвешенная сумма классов соседей (колонка score_knn),\n",
    "    для решающего дерева — доля положительных объектов в листе (колонка score_tree).\n",
    "\n",
    "5. Посчитайте площадь под ROC-кривой для каждого классификатора. Какой классификатор имеет наибольшее значение метрики AUC-ROC (укажите название столбца)? Воспользуйтесь функцией sklearn.metrics.roc_auc_score.\n",
    "\n",
    "6. Какой классификатор достигает наибольшей точности (Precision) при полноте (Recall) не менее 70% ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task №1\n",
    "*Ru*: Загрузите файл classification.csv. В нем записаны истинные классы объектов выборки (колонка true) и ответы некоторого классификатора (колонка pred).\n",
    "\n",
    "\n",
    "*En:* Download classification.csv file. It contains the true classes of objects (the 'true' column) as well as the predictions of some classifier (the 'pred' column). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true  pred\n",
       "0       1     0\n",
       "1       1     1\n",
       "2       1     1\n",
       "3       0     0\n",
       "4       1     1\n",
       "..    ...   ...\n",
       "195     0     0\n",
       "196     0     0\n",
       "197     1     0\n",
       "198     0     1\n",
       "199     0     0\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv('classification.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task №2\n",
    "*Ru*: Заполните таблицу ошибок классификации:\n",
    "    Для этого подсчитайте величины TP, FP, FN и TN согласно их определениям. Например, FP — это количество объектов, имеющих класс 0, но отнесенных алгоритмом к классу 1. Ответ в данном вопросе — четыре числа через пробел.\n",
    "\n",
    "*En:* Fill in the classification errors table: To do this, calculate the TP, FP, FN and TN values according to their definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = df['pred']\n",
    "true = df['true']\n",
    "\n",
    "pred_list = pred.values.tolist()\n",
    "true_list = true.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP, FP, FN, TN =  43 34 59 64\n"
     ]
    }
   ],
   "source": [
    "TP, FP, FN, TN = 0, 0, 0, 0\n",
    "for i in range(len(pred_list)):\n",
    "    if true_list[i] == 1:\n",
    "        if pred_list[i] == 1:\n",
    "            TP +=1\n",
    "        else: FN +=1\n",
    "    else:\n",
    "        if pred_list[i] == 1:\n",
    "            FP +=1\n",
    "        else: TN +=1\n",
    "print(\"TP, FP, FN, TN = \", TP, FP, FN, TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task №3\n",
    "*Ru*: Посчитайте основные метрики качества классификатора:\n",
    "    Accuracy (доля верно угаданных) — sklearn.metrics.accuracy_score\n",
    "    Precision (точность) — sklearn.metrics.precision_score\n",
    "    Recall (полнота) — sklearn.metrics.recall_score\n",
    "    F-мера — sklearn.metrics.f1_score\n",
    "\n",
    "\n",
    "*En:* Calculate the main quality metrics of the classifier:\n",
    "     Accuracy - sklearn.metrics.accuracy_score\n",
    "     Precision - sklearn.metrics.precision_score\n",
    "     Recall - sklearn.metrics.recall_score\n",
    "     F-measure - sklearn.metrics.f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.535 0.5584415584415584 0.4215686274509804 0.48044692737430167\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(true, pred)\n",
    "precision =precision_score(true, pred)\n",
    "recall = recall_score(true, pred)\n",
    "f1 = f1_score(true, pred)\n",
    "print(acc, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task №4\n",
    "*Ru*: Имеется четыре обученных классификатора. В файле scores.csv записаны истинные классы и значения степени принадлежности положительному классу для каждого классификатора на некоторой выборке:\n",
    "\n",
    "    для логистической регрессии — вероятность положительного класса (колонка score_logreg),\n",
    "    для SVM — отступ от разделяющей поверхности (колонка score_svm),\n",
    "    для метрического алгоритма — взвешенная сумма классов соседей (колонка score_knn),\n",
    "    для решающего дерева — доля положительных объектов в листе (колонка score_tree).\n",
    "\n",
    "*En:* The scores.csv file contains the true classes and values of the degree of membership of the positive class for the four classifiers.\n",
    "\n",
    "    for logistic regression - the probability of a positive class (column score_logreg),\n",
    "    for SVM - offset from the dividing surface (score_svm column),\n",
    "    for the metric algorithm - the weighted sum of neighbor classes (score_knn column),\n",
    "    for the decision tree, the proportion of positive objects in the sheet (score_tree column). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>score_logreg</th>\n",
       "      <th>score_svm</th>\n",
       "      <th>score_knn</th>\n",
       "      <th>score_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.683832</td>\n",
       "      <td>0.145976</td>\n",
       "      <td>0.787063</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.801966</td>\n",
       "      <td>0.239511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.382315</td>\n",
       "      <td>-0.245701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.506797</td>\n",
       "      <td>-0.137058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.488781</td>\n",
       "      <td>-0.154148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0.573801</td>\n",
       "      <td>-0.088203</td>\n",
       "      <td>0.284192</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0.624422</td>\n",
       "      <td>-0.012315</td>\n",
       "      <td>0.205437</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>0.425538</td>\n",
       "      <td>-0.135673</td>\n",
       "      <td>0.382351</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0.905270</td>\n",
       "      <td>0.583806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>0.275594</td>\n",
       "      <td>-0.422160</td>\n",
       "      <td>0.743567</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true  score_logreg  score_svm  score_knn  score_tree\n",
       "0       0      0.683832   0.145976   0.787063    0.500000\n",
       "1       1      0.801966   0.239511   1.000000    0.833333\n",
       "2       0      0.382315  -0.245701   0.000000    0.000000\n",
       "3       1      0.506797  -0.137058   0.000000    0.105263\n",
       "4       1      0.488781  -0.154148   0.000000    0.105263\n",
       "..    ...           ...        ...        ...         ...\n",
       "195     0      0.573801  -0.088203   0.284192    0.400000\n",
       "196     0      0.624422  -0.012315   0.205437    0.400000\n",
       "197     1      0.425538  -0.135673   0.382351    0.700000\n",
       "198     0      0.905270   0.583806   1.000000    1.000000\n",
       "199     0      0.275594  -0.422160   0.743567    0.642857\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pandas.read_csv('scores.csv')\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task №5\n",
    "*Ru*: Посчитайте площадь под ROC-кривой для каждого классификатора. Какой классификатор имеет наибольшее значение метрики AUC-ROC (укажите название столбца)? Воспользуйтесь функцией sklearn.metrics.roc_auc_score.\n",
    "\n",
    "*En:* Calculate the area under the ROC curve for each classifier. Which classifier has the highest AUC-ROC metric (specify column name)? Use the sklearn.metrics.roc_auc_score function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score_logreg': 0.719187675070028,\n",
       " 'score_svm': 0.7086834733893557,\n",
       " 'score_knn': 0.6351540616246498,\n",
       " 'score_tree': 0.6919267707082833}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_res = {}\n",
    "for x in df_scores.columns[1:]:\n",
    "    scores_res[x] = roc_auc_score(df_scores['true'], df_scores[x])\n",
    "scores_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression** got best AUC-ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task №6\n",
    "*Ru*: Какой классификатор достигает наибольшей точности (Precision) при полноте (Recall) не менее 70% \n",
    "\n",
    "*En:* Which classifier achieves the highest Precision with a Recall of at least 70% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score_logreg': 0.6302521008403361,\n",
       " 'score_svm': 0.6228070175438597,\n",
       " 'score_knn': 0.6065573770491803,\n",
       " 'score_tree': 0.6517857142857143}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_precision = {}\n",
    "for x in df_scores.columns[1:]:\n",
    "    curve = precision_recall_curve(df_scores['true'], df_scores[x])\n",
    "    \n",
    "    #This three arrays in curve.\n",
    "    #They correspond to three indicators: precision, recall and thresholds.\n",
    "    precisions = []\n",
    "    for i in range(len(curve[1])):\n",
    "        if curve[1][i] >  0.7:\n",
    "            precisions.append(curve[0][i])\n",
    "    best_precision[x] = max(precisions)        \n",
    "    \n",
    "best_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision tree** beats other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
